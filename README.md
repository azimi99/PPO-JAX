## PPO in JAX
Here are some Gymnasium environments with continuous observation spaces and discrete action spaces suitable for benchmarking this PPO JAX implementation:

- `CartPole-v1`
- `MountainCar-v0`
- `Acrobot-v1`
- `LunarLander-v3`


Coming soon: Results
Coming soon: technical writeup

Cheers!

## References

- **Proximal Policy Optimization Algorithms**  
    Schulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. (2017).  
    [arXiv:1707.06347](https://arxiv.org/abs/1707.06347)

- **CleanRL: High-quality single-file implementations of RL algorithms**  
    [CleanRL GitHub Repository](https://github.com/vwxyzjn/cleanrl)
