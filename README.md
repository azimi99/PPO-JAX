## PPO in JAX
Here are some Gymnasium environments with continuous observation spaces and discrete action spaces suitable for benchmarking this PPO JAX implementation:

- `CartPole-v1`
- `MountainCar-v0`
- `Acrobot-v1`
- `LunarLander-v3`
## Results
Check out our experiment results and interactive visualizations below:

[Experiment Report & Visualizations](https://api.wandb.ai/links/azimi/izj0gno5)

## Technical Writeup

A detailed technical writeup is coming soon.

Cheers!

## References

- **Proximal Policy Optimization Algorithms**  
    Schulman, J., Wolski, F., Dhariwal, P., Radford, A., & Klimov, O. (2017).  
    [arXiv:1707.06347](https://arxiv.org/abs/1707.06347)

- **CleanRL: High-quality single-file implementations of RL algorithms**  
    [CleanRL GitHub Repository](https://github.com/vwxyzjn/cleanrl)
